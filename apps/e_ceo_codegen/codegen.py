"""LLM powered Manim + CAS generation wired for the deterministic pipeline."""

from __future__ import annotations

import base64
import json
import os
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional

import tomllib
from dotenv import load_dotenv
from openai import OpenAI

from pipelines.utils import extract_jobs_and_code

BASE_DIR = Path(__file__).resolve().parent
CONFIG_DIR = BASE_DIR.parent.parent / "configs"
SYSTEM_PROMPT_PATH = BASE_DIR / "system_prompt.txt"

load_dotenv()


@dataclass
class CodegenResult:
    code_path: Path
    manim_path: Path
    jobs_path: Path
    jobs: List[Dict[str, Any]]
    manim_code: str
    status: str

    def as_dict(self) -> Dict[str, Any]:
        return {
            "code_path": str(self.code_path),
            "manim_path": str(self.manim_path),
            "jobs_path": str(self.jobs_path),
            "jobs": self.jobs,
            "manim_code": self.manim_code,
            "status": self.status,
        }


def load_system_prompt() -> str:
    if SYSTEM_PROMPT_PATH.exists():
        return SYSTEM_PROMPT_PATH.read_text(encoding="utf-8")
    return "You are a Manim+CAS code generator."


def _load_openai_config() -> Dict[str, Any]:
    cfg_path = CONFIG_DIR / "openai.toml"
    if not cfg_path.exists():
        return {"model": "gpt-4o-mini", "temperature": 0.0}
    with cfg_path.open("rb") as fh:
        cfg = tomllib.load(fh)
    section = cfg.get("ceo_codegen", {})
    default = cfg.get("default", {})
    model = section.get("model") or default.get("model") or "gpt-4o-mini"
    temperature = section.get("temperature", 0.0)
    return {"model": model, "temperature": float(temperature)}


def _encode_image(path: Path) -> Optional[Dict[str, str]]:
    if not path.exists():
        return None
    mime = "image/jpeg"
    ext = path.suffix.lower()
    if ext == ".png":
        mime = "image/png"
    try:
        data = base64.b64encode(path.read_bytes()).decode("utf-8")
    except Exception:
        return None
    return {"type": "image_url", "image_url": {"url": f"data:{mime};base64,{data}"}}


def _gather_image_parts(paths: Iterable[Path]) -> List[Dict[str, Any]]:
    parts: List[Dict[str, Any]] = []
    for candidate in paths:
        encoded = _encode_image(candidate)
        if encoded:
            parts.append(encoded)
    return parts


def _default_image_candidates(problem_dir: Path) -> List[Path]:
    candidates: List[Path] = []
    for name in ["problem_input.jpg", "problem_input.png", "problem.jpg"]:
        p = problem_dir / name
        if p.exists():
            candidates.append(p)
    candidates.extend(sorted(problem_dir.glob("*__pic_i*.jpg")))
    candidates.extend(sorted(problem_dir.glob("*__pic_i*.png")))
    return candidates


def _placeholder_output(problem_dir: Path, reason: str) -> CodegenResult:
    code_path = problem_dir / "codegen_output.py"
    manim_path = problem_dir / "manim_draft.py"
    jobs_path = problem_dir / "cas_jobs.json"

    placeholder = (
        "# Placeholder generated by ceo_codegen\n"
        f"# Reason: {reason}\n\n"
        "from manim import *\n\n\n"
        "class ProblemScene(Scene):\n"
        "    def construct(self):\n"
        "        self.add(Text('Fill in Manim code based on spec.json').scale(0.6))\n"
    )

    code_path.write_text(placeholder + "\n---CAS-JOBS---\n[]\n", encoding="utf-8")
    manim_path.write_text(placeholder, encoding="utf-8")
    jobs_path.write_text("[]\n", encoding="utf-8")

    return CodegenResult(
        code_path=code_path,
        manim_path=manim_path,
        jobs_path=jobs_path,
        jobs=[],
        manim_code=placeholder,
        status="placeholder",
    )


def run_ceo_codegen(
    problem_dir: str | Path,
    *,
    spec_path: str | Path | None = None,
    ocr_json_path: str | Path | None = None,
    vector_json_path: str | Path | None = None,
    image_paths: Optional[List[str]] = None,
    force: bool = False,
    model: Optional[str] = None,
    temperature: Optional[float] = None,
    client: Optional[OpenAI] = None,
) -> Dict[str, Any]:
    """Generate Manim code and CAS jobs for the solved spec."""

    problem_dir_path = Path(problem_dir).expanduser().resolve()
    spec_path = Path(spec_path or (problem_dir_path / "spec.json"))
    ocr_json_path = Path(ocr_json_path or (problem_dir_path / "problem.json"))
    vector_json_path = Path(vector_json_path) if vector_json_path else problem_dir_path / f"{problem_dir_path.name}_vector.json"
    if not vector_json_path.exists():
        vector_json_path = None

    if not spec_path.exists():
        raise FileNotFoundError(f"spec.json not found at {spec_path}")
    if not ocr_json_path.exists():
        raise FileNotFoundError(f"problem.json not found at {ocr_json_path}")

    spec = json.loads(spec_path.read_text(encoding="utf-8"))
    if spec.get("status") != "solved":
        raise ValueError("spec.json must be solved by geo_compute before ceo_codegen")

    ocr_data = json.loads(ocr_json_path.read_text(encoding="utf-8"))
    vector_data = {}
    if vector_json_path and vector_json_path.exists():
        try:
            vector_data = json.loads(vector_json_path.read_text(encoding="utf-8"))
        except Exception:
            vector_data = {}

    code_path = problem_dir_path / "codegen_output.py"
    manim_path = problem_dir_path / "manim_draft.py"
    jobs_path = problem_dir_path / "cas_jobs.json"

    if not force and code_path.exists() and manim_path.exists() and jobs_path.exists():
        jobs = json.loads(jobs_path.read_text(encoding="utf-8"))
        manim_code = manim_path.read_text(encoding="utf-8")
        return CodegenResult(code_path, manim_path, jobs_path, jobs, manim_code, "reused").as_dict()

    cfg = _load_openai_config()
    model_name = model or cfg.get("model", "gpt-4o-mini")
    temp = temperature if temperature is not None else cfg.get("temperature", 0.0)

    if client is None:
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            return _placeholder_output(problem_dir_path, "OPENAI_API_KEY not configured").as_dict()
        client = OpenAI(api_key=api_key)

    images: List[Path] = []
    if image_paths:
        images.extend(Path(p) for p in image_paths)
    else:
        images.extend(_default_image_candidates(problem_dir_path))

    user_sections = [
        "문제의 OCR JSON, 벡터 요약 및 해결된 spec.json을 참고하여 Manim 코드와 ---CAS-JOBS--- JSON 배열을 생성하세요.",
        "[OCR JSON]\n" + json.dumps(ocr_data, ensure_ascii=False, indent=2),
        "[Vector]\n" + json.dumps(vector_data, ensure_ascii=False, indent=2),
        "[Solved Spec]\n" + json.dumps(spec, ensure_ascii=False, indent=2),
    ]

    user_parts: List[Dict[str, Any]] = [{"type": "text", "text": "\n\n".join(user_sections)}]
    user_parts.extend(_gather_image_parts(images))

    response = client.chat.completions.create(
        model=model_name,
        messages=[
            {"role": "system", "content": load_system_prompt()},
            {"role": "user", "content": user_parts},
        ],
        temperature=temp,
    )

    content = response.choices[0].message.content or ""

    try:
        jobs_raw, manim_code = extract_jobs_and_code(content)
    except Exception as exc:
        placeholder = _placeholder_output(problem_dir_path, f"LLM output parsing failed: {exc}")
        return placeholder.as_dict()

    code_path.write_text(content, encoding="utf-8")
    manim_path.write_text(manim_code, encoding="utf-8")
    jobs_path.write_text(json.dumps(jobs_raw, ensure_ascii=False, indent=2) + "\n", encoding="utf-8")

    return CodegenResult(code_path, manim_path, jobs_path, jobs_raw, manim_code, "generated").as_dict()
