"""LLM powered Manim + CAS generation wired for the deterministic pipeline."""

from __future__ import annotations

import base64
import json
import os
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional

import tomllib
from dotenv import load_dotenv
from openai import OpenAI

from pipelines.utils import extract_jobs_and_code

BASE_DIR = Path(__file__).resolve().parent
CONFIG_DIR = BASE_DIR.parent.parent / "configs"
SYSTEM_PROMPT_PATH = BASE_DIR / "system_prompt.txt"

load_dotenv()


@dataclass
class CodegenResult:
    code_path: Path
    manim_path: Path
    jobs_path: Path
    jobs: List[Dict[str, Any]]
    manim_code: str
    status: str

    def as_dict(self) -> Dict[str, Any]:
        return {
            "code_path": str(self.code_path),
            "manim_path": str(self.manim_path),
            "jobs_path": str(self.jobs_path),
            "jobs": self.jobs,
            "manim_code": self.manim_code,
            "status": self.status,
        }


def load_system_prompt() -> str:
    if SYSTEM_PROMPT_PATH.exists():
        return SYSTEM_PROMPT_PATH.read_text(encoding="utf-8")
    return "You are a Manim+CAS code generator."


def _load_openai_config() -> Dict[str, Any]:
    cfg_path = CONFIG_DIR / "openai.toml"
    if not cfg_path.exists():
        return {"model": "gpt-4o-mini", "temperature": 0.0}
    with cfg_path.open("rb") as fh:
        cfg = tomllib.load(fh)
    section = cfg.get("cas_codegen") or cfg.get("ceo_codegen", {})
    default = cfg.get("default", {})
    model = section.get("model") or default.get("model") or "gpt-4o-mini"
    temperature = section.get("temperature", 0.0)
    return {"model": model, "temperature": float(temperature)}


def _encode_image(path: Path) -> Optional[Dict[str, str]]:
    if not path.exists():
        return None
    mime = "image/jpeg"
    ext = path.suffix.lower()
    if ext == ".png":
        mime = "image/png"
    try:
        data = base64.b64encode(path.read_bytes()).decode("utf-8")
    except Exception:
        return None
    return {"type": "image_url", "image_url": {"url": f"data:{mime};base64,{data}"}}


def _gather_image_parts(paths: Iterable[Path]) -> List[Dict[str, Any]]:
    parts: List[Dict[str, Any]] = []
    for candidate in paths:
        encoded = _encode_image(candidate)
        if encoded:
            parts.append(encoded)
    return parts


def _select_problem_image(problem_dir: Path) -> Optional[Path]:
    for name in ["problem.jpg", "problem_input.jpg", "problem_input.png"]:
        candidate = problem_dir / name
        if candidate.exists():
            return candidate
    return None


def _placeholder_output(problem_dir: Path, reason: str) -> CodegenResult:
    code_path = problem_dir / "codegen_output.py"
    manim_path = problem_dir / "manim_draft.py"
    jobs_path = problem_dir / "cas_jobs.json"

    placeholder = (
        "# Placeholder generated by cas_codegen\n"
        f"# Reason: {reason}\n\n"
        "from manim import *\n\n\n"
        "class ProblemScene(Scene):\n"
        "    def construct(self):\n"
        "        self.add(Text('Fill in Manim code based on spec.json').scale(0.6))\n"
    )

    code_path.write_text(placeholder + "\n---CAS-JOBS---\n[]\n", encoding="utf-8")
    manim_path.write_text(placeholder, encoding="utf-8")
    jobs_path.write_text("[]\n", encoding="utf-8")

    return CodegenResult(
        code_path=code_path,
        manim_path=manim_path,
        jobs_path=jobs_path,
        jobs=[],
        manim_code=placeholder,
        status="placeholder",
    )


def run_cas_codegen(
    problem_dir: str | Path,
    *,
    spec_path: str | Path | None = None,
    ocr_json_path: str | Path | None = None,
    image_path: Optional[str] = None,
    force: bool = False,
    model: Optional[str] = None,
    temperature: Optional[float] = None,
    client: Optional[OpenAI] = None,
) -> Dict[str, Any]:
    """Generate Manim code and CAS jobs for the solved spec."""

    problem_dir_path = Path(problem_dir).expanduser().resolve()
    spec_path = Path(spec_path or (problem_dir_path / "spec.json"))
    ocr_json_path = Path(ocr_json_path or (problem_dir_path / "problem.json"))
    image_candidate = Path(image_path).expanduser() if image_path else _select_problem_image(problem_dir_path)
    if image_candidate and not image_candidate.exists():
        image_candidate = _select_problem_image(problem_dir_path)

    if not spec_path.exists():
        raise FileNotFoundError(f"spec.json not found at {spec_path}")
    if not ocr_json_path.exists():
        raise FileNotFoundError(f"problem.json not found at {ocr_json_path}")

    spec = json.loads(spec_path.read_text(encoding="utf-8"))
    if spec.get("status") != "solved":
        raise ValueError("spec.json must be solved by geo_compute before cas_codegen")

    ocr_data = json.loads(ocr_json_path.read_text(encoding="utf-8"))

    code_path = problem_dir_path / "codegen_output.py"
    manim_path = problem_dir_path / "manim_draft.py"
    jobs_path = problem_dir_path / "cas_jobs.json"

    if not force and code_path.exists() and manim_path.exists() and jobs_path.exists():
        jobs = json.loads(jobs_path.read_text(encoding="utf-8"))
        manim_code = manim_path.read_text(encoding="utf-8")
        return CodegenResult(code_path, manim_path, jobs_path, jobs, manim_code, "reused").as_dict()

    cfg = _load_openai_config()
    model_name = model or cfg.get("model", "gpt-4o-mini")
    temp = temperature if temperature is not None else cfg.get("temperature", 0.0)

    if client is None:
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            return _placeholder_output(problem_dir_path, "OPENAI_API_KEY not configured").as_dict()
        client = OpenAI(api_key=api_key)

    images: List[Path] = []
    if image_candidate:
        images.append(image_candidate)

    user_sections = [
        "문제의 OCR JSON과 해결된 spec.json을 참고하여 Manim 코드와 ---CAS-JOBS--- JSON 배열을 생성하세요.",
        "spec.json에 기록된 좌표와 구조를 그대로 사용하여 도형을 구성하고, 추가 좌표를 임의로 만들지 마세요.",
        "[OCR JSON]\n" + json.dumps(ocr_data, ensure_ascii=False, indent=2),
        "[Solved Spec]\n" + json.dumps(spec, ensure_ascii=False, indent=2),
    ]

    user_parts: List[Dict[str, Any]] = [{"type": "text", "text": "\n\n".join(user_sections)}]
    user_parts.extend(_gather_image_parts(images))

    response = client.chat.completions.create(
        model=model_name,
        messages=[
            {"role": "system", "content": load_system_prompt()},
            {"role": "user", "content": user_parts},
        ],
        temperature=temp,
    )

    content = response.choices[0].message.content or ""

    try:
        jobs_raw, manim_code = extract_jobs_and_code(content)
    except Exception as exc:
        placeholder = _placeholder_output(problem_dir_path, f"LLM output parsing failed: {exc}")
        return placeholder.as_dict()

    code_path.write_text(content, encoding="utf-8")
    manim_path.write_text(manim_code, encoding="utf-8")
    jobs_path.write_text(json.dumps(jobs_raw, ensure_ascii=False, indent=2) + "\n", encoding="utf-8")

    return CodegenResult(code_path, manim_path, jobs_path, jobs_raw, manim_code, "generated").as_dict()
