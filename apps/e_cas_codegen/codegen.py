"""LLM powered Manim + CAS generation for the deterministic geo pipeline."""

from __future__ import annotations

import base64
import json
import os
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional

import tomllib
from dotenv import load_dotenv
from openai import OpenAI

from pipelines.utils import extract_jobs_and_code

BASE_DIR = Path(__file__).resolve().parent
CONFIG_DIR = BASE_DIR.parent.parent / "configs"
SYSTEM_PROMPT_PATH = BASE_DIR / "system_prompt.txt"

load_dotenv()


@dataclass
class CodegenResult:
    code_path: Path
    manim_path: Path
    jobs_path: Path
    jobs: List[Dict[str, Any]]
    manim_code: str
    status: str

    def as_dict(self) -> Dict[str, Any]:
        return {
            "code_path": str(self.code_path),
            "manim_path": str(self.manim_path),
            "jobs_path": str(self.jobs_path),
            "jobs": self.jobs,
            "manim_code": self.manim_code,
            "status": self.status,
        }


def load_system_prompt() -> str:
    if SYSTEM_PROMPT_PATH.exists():
        return SYSTEM_PROMPT_PATH.read_text(encoding="utf-8")
    return "You are a Manim+CAS code generator that strictly follows spec.json coordinates."


def _load_openai_config() -> Dict[str, Any]:
    cfg_path = CONFIG_DIR / "openai.toml"
    if not cfg_path.exists():
        return {"model": "gpt-4o-mini", "temperature": 0.0}
    with cfg_path.open("rb") as fh:
        cfg = tomllib.load(fh)
    section = cfg.get("cas_codegen", {})
    fallback = cfg.get("default", {})
    model = section.get("model") or fallback.get("model") or "gpt-4o-mini"
    temperature = section.get("temperature", fallback.get("temperature", 0.0))
    return {"model": model, "temperature": float(temperature)}


def _encode_image(path: Path) -> Optional[Dict[str, Any]]:
    if not path.exists():
        return None
    mime = "image/jpeg"
    ext = path.suffix.lower()
    if ext == ".png":
        mime = "image/png"
    try:
        data = base64.b64encode(path.read_bytes()).decode("utf-8")
    except Exception:
        return None
    return {"type": "image_url", "image_url": {"url": f"data:{mime};base64,{data}"}}


def _gather_image_parts(paths: Iterable[Path]) -> List[Dict[str, Any]]:
    parts: List[Dict[str, Any]] = []
    for candidate in paths:
        encoded = _encode_image(candidate)
        if encoded:
            parts.append(encoded)
    return parts


def _default_image_candidates(problem_dir: Path) -> List[Path]:
    candidates: List[Path] = []
    primary = problem_dir / "problem.jpg"
    if primary.exists():
        candidates.append(primary)
    else:
        fallback = problem_dir / "problem_input.jpg"
        if fallback.exists():
            candidates.append(fallback)
    candidates.extend(sorted(problem_dir.glob("*__pic_i*.jpg")))
    candidates.extend(sorted(problem_dir.glob("*__pic_i*.png")))
    return candidates


def _placeholder_output(problem_dir: Path, reason: str) -> CodegenResult:
    code_path = problem_dir / "codegen_output.py"
    manim_path = problem_dir / "manim_draft.py"
    jobs_path = problem_dir / "cas_jobs.json"

    placeholder = (
        "# Placeholder generated by cas_codegen\n"
        f"# Reason: {reason}\n\n"
        "from manim import *\n\n\n"
        "class ProblemScene(Scene):\n"
        "    def construct(self):\n"
        "        self.add(Text('Fill in Manim code based on spec.json').scale(0.6))\n"
    )

    code_path.write_text(placeholder + "\n---CAS-JOBS---\n[]\n", encoding="utf-8")
    manim_path.write_text(placeholder, encoding="utf-8")
    jobs_path.write_text("[]\n", encoding="utf-8")

    return CodegenResult(
        code_path=code_path,
        manim_path=manim_path,
        jobs_path=jobs_path,
        jobs=[],
        manim_code=placeholder,
        status="placeholder",
    )


def run_cas_codegen(
    problem_dir: str | Path,
    *,
    spec_path: str | Path | None = None,
    ocr_json_path: str | Path | None = None,
    image_paths: Optional[List[str]] = None,
    force: bool = False,
    model: Optional[str] = None,
    temperature: Optional[float] = None,
    client: Optional[OpenAI] = None,
) -> Dict[str, Any]:
    """Generate Manim code and CAS jobs directly from ``spec.json`` + OCR data."""

    problem_dir_path = Path(problem_dir).expanduser().resolve()
    spec_path = Path(spec_path or (problem_dir_path / "spec.json"))
    ocr_json_path = Path(ocr_json_path or (problem_dir_path / "problem.json"))

    if not spec_path.exists():
        raise FileNotFoundError(f"spec.json not found at {spec_path}")
    if not ocr_json_path.exists():
        raise FileNotFoundError(f"problem.json not found at {ocr_json_path}")

    spec = json.loads(spec_path.read_text(encoding="utf-8"))
    if spec.get("status") != "solved":
        raise ValueError("spec.json must be solved by geo_compute before cas_codegen")

    ocr_data = json.loads(ocr_json_path.read_text(encoding="utf-8"))

    code_path = problem_dir_path / "codegen_output.py"
    manim_path = problem_dir_path / "manim_draft.py"
    jobs_path = problem_dir_path / "cas_jobs.json"

    if not force and code_path.exists() and manim_path.exists() and jobs_path.exists():
        jobs = json.loads(jobs_path.read_text(encoding="utf-8"))
        manim_code = manim_path.read_text(encoding="utf-8")
        return CodegenResult(code_path, manim_path, jobs_path, jobs, manim_code, "reused").as_dict()

    cfg = _load_openai_config()
    model_name = model or cfg.get("model", "gpt-4o-mini")
    temp = temperature if temperature is not None else cfg.get("temperature", 0.0)

    if client is None:
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            return _placeholder_output(problem_dir_path, "OPENAI_API_KEY not configured").as_dict()
        client = OpenAI(api_key=api_key)

    images: List[Path] = []
    if image_paths:
        images.extend(Path(p) for p in image_paths)
    else:
        images.extend(_default_image_candidates(problem_dir_path))

    user_sections = [
        "spec.json의 좌표와 조건을 그대로 사용하여 Manim Scene과 ---CAS-JOBS--- 배열을 작성하세요.",
        "모든 도형 좌표는 spec.json의 points 값을 사용하고, 새로운 좌표 계산은 금지입니다.",
        "증명/설명 논리는 OCR JSON의 텍스트를 참고해 구성하세요.",
        "[OCR JSON]\n" + json.dumps(ocr_data, ensure_ascii=False, indent=2),
        "[Solved Spec]\n" + json.dumps(spec, ensure_ascii=False, indent=2),
    ]

    user_parts: List[Dict[str, Any]] = [{"type": "text", "text": "\n\n".join(user_sections)}]
    user_parts.extend(_gather_image_parts(images))

    response = client.chat.completions.create(
        model=model_name,
        messages=[
            {"role": "system", "content": load_system_prompt()},
            {"role": "user", "content": user_parts},
        ],
        temperature=temp,
    )

    content = response.choices[0].message.content or ""

    try:
        jobs_raw, manim_code = extract_jobs_and_code(content)
    except Exception as exc:
        placeholder = _placeholder_output(problem_dir_path, f"LLM output parsing failed: {exc}")
        return placeholder.as_dict()

    code_path.write_text(content, encoding="utf-8")
    manim_path.write_text(manim_code, encoding="utf-8")
    jobs_path.write_text(json.dumps(jobs_raw, ensure_ascii=False, indent=2) + "\n", encoding="utf-8")

    return CodegenResult(code_path, manim_path, jobs_path, jobs_raw, manim_code, "generated").as_dict()


__all__ = ["run_cas_codegen", "load_system_prompt"]
